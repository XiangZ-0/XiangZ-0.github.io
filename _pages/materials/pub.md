# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TPAMI 2022</div><img src='_pages/materials/imgs/ESAI.gif' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Learning to See Through with Events](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9973388)

Lei Yu<sup>‚Ä†</sup>, **Xiang Zhang**, Wei Liao, Wen Yang, Gui-Song Xia

 \[[Code](https://github.com/dvs-whu/E-SAI)\] \[[Dataset](https://drive.google.com/drive/folders/1JVA06QYaQwG88BcAIJwjUGjyItR_UDjC)\] \[[Bilibili](https://www.bilibili.com/video/BV1JL411M7n5/?spm_id_from=333.999.0.0&vd_source=019e4ae5ab90b4c54207081152e55aae)\]
- An event-based synthetic aperture imaging (E-SAI) algorithm is proposed to see through dense occlusions even under extreme lighting conditions. 
- A hybrid network composed of an spiking encoder and a convolutional decoder is designed to mitigate the disturbances from occlusions and guarantee the overall reconstruction performance.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2022</div><img src='_pages/materials/imgs/EVDI.gif' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Unifying Motion Deblurring and Frame Interpolation with Events](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Unifying_Motion_Deblurring_and_Frame_Interpolation_With_Events_CVPR_2022_paper.pdf)

**Xiang Zhang**, Lei Yu<sup>‚Ä†</sup>

\[[Code](https://github.com/XiangZ-0/EVDI)\] \[[Youtube](https://www.youtube.com/watch?v=ih7o5PawSCw&t=1s)\]
- We present a unified framework for event-based video deblurring and interpolation (EVDI). 
- By utilizing the constraints between cross-modal frames and events, a fully self-supervised learning method is proposed to enable network training with real-world data without requiring ground-truth images.

</div>
</div>

- [Learning to Super-Resolve Blurry Images with Events](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10029887), Lei Yu<sup>‚Ä†</sup>, Bishan Wang, **Xiang Zhang**, Haijian Zhang, Wen Yang, Jianzhuang Liu, Gui-Song Xia, **IEEE TPAMI 2023**

- [Spiking Sparse Recovery with Non-convex Penalties](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10007054), **Xiang Zhang**, Lei Yu<sup>‚Ä†</sup>, Gang Zheng, Yonina C. Eldar, **IEEE TSP 2022**

- [Synthetic Aperture Imaging with Events and Frames](https://openaccess.thecvf.com/content/CVPR2022/papers/Liao_Synthetic_Aperture_Imaging_With_Events_and_Frames_CVPR_2022_paper.pdf), Wei Liao<sup>\*</sup>, **Xiang Zhang**<sup>\*</sup>, Lei Yu<sup>‚Ä†</sup>, Shijie Lin, Wen Yang, Ning Qiao, **CVPR 2022** \| \[[Code](https://github.com/smjsc/EF-SAI)\] \[[Dataset](https://onedrive.live.com/?authkey=%21AMvAPOnuudsYx1I&id=7ABD0A750B262518%214850&cid=7ABD0A750B262518)\]

- [Event-based Synthetic Aperture Imaging with a Hybrid Network](https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Event-Based_Synthetic_Aperture_Imaging_With_a_Hybrid_Network_CVPR_2021_paper.pdf), **Xiang Zhang**<sup>\*</sup>, Wei Liao<sup>\*</sup>, Lei Yu<sup>‚Ä†</sup>, Wen Yang, Gui-Song Xia, **CVPR 2021** <font color='red'> (Oral, Best Paper Candidate) </font> \| \[[Code](https://github.com/dvs-whu/E-SAI)\] \[[Dataset](https://drive.google.com/drive/folders/1JVA06QYaQwG88BcAIJwjUGjyItR_UDjC)\] \[[Youtube](https://www.youtube.com/watch?v=a81xBe2ZX_8)\]  

<sup>\*</sup> means equal contribution and <sup>‚Ä†</sup> indicates my supervisor.


<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2016</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div>

- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020** -->